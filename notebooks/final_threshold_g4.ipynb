{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyro-ppl==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "from src.posterior_networks.PosteriorNetwork import PosteriorNetwork\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from src.dataset_manager.ClassificationDataset import MapillaryDataset\n",
    "from src.results_manager.metrics_prior import confidence, brier_score, anomaly_detection\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from src.posterior_networks.config import config\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7458,  3970, 21210,  9894])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /nfs/homedirs/zhz/.cache/torch/hub/pytorch_vision_main\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/lab/project-1/train_label.csv')\n",
    "val_df = pd.read_csv('/lab/project-1/val_label.csv')\n",
    "test_df = pd.read_csv('/lab/project-1/test_label.csv')\n",
    "regions = set(['g1', 'g2', 'g3', 'g4', 'g5', 'g6'])\n",
    "classes = set(['regu', 'warn', 'comp', 'info'])\n",
    "full_path = '/lab/project-1/final_models/resnet18_oodg4_lat8_reg1e4_dens6_batch64_lr1e4__'\n",
    "# full_path = '../../src/posterior_networks/models/resnet18_oodg3g4_RandAug_ops3_mag3_bins31'\n",
    "\n",
    "config = json.load(open(f'{full_path}/config.json'))\n",
    "\n",
    "\n",
    "# if 'class_encoding' in config: \n",
    "#     class_encoding = config['class_encoding']\n",
    "# else:\n",
    "#     class_encoding = {c: i for i, c in enumerate(sorted(train_df.label.unique()))}\n",
    "\n",
    "if \"N\" in config:\n",
    "    N = config['N']\n",
    "else:\n",
    "    N = train_df.label_encoded.value_counts().sort_index().values\n",
    "N = torch.tensor(N)\n",
    "\n",
    "print(N)\n",
    "\n",
    "model = PosteriorNetwork(N=N,\n",
    "                         n_classes=config['num_classes'],\n",
    "                         hidden_dims=config['hidden_dims'],\n",
    "                         kernel_dim=None,\n",
    "                         latent_dim=config['latent_dim'],\n",
    "                         architecture=config['architecture'],\n",
    "                         k_lipschitz=config['k_lipschitz'],\n",
    "                         no_density=config['no_density'],\n",
    "                         density_type=config['density_type'],\n",
    "                         n_density=config['n_density'],\n",
    "                         budget_function=config['budget_function'],\n",
    "                         batch_size=config['batch_size'],\n",
    "                         lr=config['lr'],\n",
    "                         loss=config['loss'],\n",
    "                         dropout=config['dropout'],\n",
    "                         regr=config['regr'],\n",
    "                         seed=config['seed'])\n",
    "\n",
    "# model.load_state_dict(torch.load(f'{full_path}/best_model.pth')['model_state_dict'])\n",
    "model.cuda()\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "val_dataset = MapillaryDataset(val_df, transform = transform_val_test)\n",
    "\n",
    "# use a dict to map ground truth vector of ID and OOD\n",
    "ood_regions_classes = set(config['ood_regions'].split(','))\n",
    "ood_regions = ood_regions_classes.intersection(regions)\n",
    "ood_classes = ood_regions_classes.intersection(classes)\n",
    "\n",
    "grd_truth = torch.tensor(val_df.region.isin(ood_regions).astype(int).values) # 0 as ID, 1 as OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batched_radial_flow'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['density_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if error in model loading:\n",
    "dict = torch.load(f'{full_path}/best_model.pth')['model_state_dict']\n",
    "older_val = dict['sequential.11.weight']\n",
    "dict['sequential.12.weight'] = dict.pop('sequential.11.weight')\n",
    "older_val = dict['sequential.11.bias']\n",
    "dict['sequential.12.bias'] = dict.pop('sequential.11.bias')\n",
    "torch.save(full_path,'./model_changed.pth')\n",
    "model.load_state_dict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "@torch.no_grad()\n",
    "def compute_X_Y_alpha(model, loader, alpha_only=False):\n",
    "    for batch_index, (X, Y) in tqdm(enumerate(loader)):\n",
    "        X, Y = X.to('cuda'), Y.to('cuda')\n",
    "        # print(X.shape)\n",
    "        alpha_pred = model(X, None, return_output='alpha', compute_loss=False)\n",
    "        # print('batch:', batch_index)\n",
    "        if batch_index == 0:\n",
    "            X_duplicate_all = X.to(\"cpu\")\n",
    "            orig_Y_all = Y.to(\"cpu\")\n",
    "            alpha_pred_all = alpha_pred.to(\"cpu\")\n",
    "        else:\n",
    "            X_duplicate_all = torch.cat([X_duplicate_all, X.to('cpu')], dim=0)\n",
    "            orig_Y_all = torch.cat([orig_Y_all, Y.to('cpu')], dim=0)\n",
    "            alpha_pred_all = torch.cat([alpha_pred_all, alpha_pred.to('cpu')], dim=0)\n",
    "    if alpha_only:\n",
    "        return alpha_pred_all\n",
    "    else:\n",
    "        return orig_Y_all, X_duplicate_all, alpha_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper___slow_conv2d_forward)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m val_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(val_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, num_workers\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, pin_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m----> 4\u001b[0m val_orig_Y_all, val_X_duplicate_all, val_alpha_pred_all \u001b[39m=\u001b[39m compute_X_Y_alpha(model, val_loader)\n",
      "File \u001b[0;32m~/anaconda3/envs/postnet/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn [25], line 7\u001b[0m, in \u001b[0;36mcompute_X_Y_alpha\u001b[0;34m(model, loader, alpha_only)\u001b[0m\n\u001b[1;32m      5\u001b[0m X, Y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m), Y\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39m# print(X.shape)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m alpha_pred \u001b[39m=\u001b[39m model(X, \u001b[39mNone\u001b[39;49;00m, return_output\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39malpha\u001b[39;49m\u001b[39m'\u001b[39;49m, compute_loss\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      8\u001b[0m \u001b[39m# print('batch:', batch_index)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m batch_index \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/postnet/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/uncertainty-quantification/src/results_manager/../../src/posterior_networks/PosteriorNetwork.py:108\u001b[0m, in \u001b[0;36mPosteriorNetwork.forward\u001b[0;34m(self, input, soft_output, return_output, compute_loss)\u001b[0m\n\u001b[1;32m    105\u001b[0m     N \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN\n\u001b[1;32m    107\u001b[0m \u001b[39m# Forward\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m zk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msequential(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_density:  \u001b[39m# Ablated model without density estimation\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_classifier(zk)\n",
      "File \u001b[0;32m~/anaconda3/envs/postnet/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/postnet/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/postnet/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/postnet/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/postnet/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper___slow_conv2d_forward)"
     ]
    }
   ],
   "source": [
    "# find a threshold for g4 in val, and then test it on testset\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, num_workers=6, pin_memory=True)\n",
    "model.eval()\n",
    "val_orig_Y_all, val_X_duplicate_all, val_alpha_pred_all = compute_X_Y_alpha(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.3329)\n"
     ]
    }
   ],
   "source": [
    "print((val_alpha_pred_all.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_false_table(grd_truth, pred):\n",
    "    table = [[[] for i in range(2)] for i in range(2)] # \n",
    "    for i in range(len(grd_truth)):\n",
    "        if grd_truth[i] == 1:\n",
    "            if pred[i] == 1: # True positive\n",
    "                table[0][0].append(i)\n",
    "            elif pred[i] == 0: # False negative\n",
    "                table[0][1].append(i)\n",
    "            else:\n",
    "                KeyError('wrong number')\n",
    "        elif grd_truth[i] == 0:\n",
    "            if pred[i] == 1: # False positive\n",
    "                table[1][0].append(i)\n",
    "            elif pred[i] == 0: # True negative\n",
    "                table[1][1].append(i)\n",
    "            else:\n",
    "                KeyError('wrong number')\n",
    "        else:\n",
    "            KeyError('wrong number')\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "threshold:1.1313131313131313, balanced accuracy:0.5757527677076391, accuracy:0.5025345937799699, area under curve:0.575752767707639\n",
      "TP: 296\n",
      "FN: 153\n",
      "FP: 3478\n",
      "TN 3372\n"
     ]
    }
   ],
   "source": [
    "# use maximum of alpha as threshold\n",
    "# torch.concat(torch.max(alpha_pred_all, dim=1).values, grd_truth)\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, roc_auc_score\n",
    "max_alpha = torch.max(val_alpha_pred_all, dim=1).values\n",
    "output = [[],[],[],[]]\n",
    "for threshold in np.linspace(1,14,100):\n",
    "    pred = (torch.max(val_alpha_pred_all, dim=1).values < threshold).int()\n",
    "    acc = balanced_accuracy_score(grd_truth, pred)\n",
    "    acc2 = accuracy_score(grd_truth, pred)\n",
    "    auc = roc_auc_score(grd_truth, pred)\n",
    "    output[0].append(threshold)\n",
    "    output[1].append(acc)\n",
    "    output[2].append(acc2)\n",
    "    output[3].append(auc)\n",
    "\n",
    "index = output[1].index(max(output[1]))\n",
    "print(\"###\")\n",
    "print(f'threshold:{output[0][index]}, balanced accuracy:{output[1][index]}, accuracy:{output[2][index]}, area under curve:{output[3][index]}')\n",
    "\n",
    "pred = (torch.max(val_alpha_pred_all, dim=1).values < output[0][index]).int()\n",
    "table = true_false_table(grd_truth, pred)\n",
    "print('TP:',len(table[0][0]))\n",
    "print('FN:',len(table[0][1]))\n",
    "print('FP:',len(table[1][0]))\n",
    "print('TN',len(table[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [01:06,  9.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# see the performance on the test set\n",
    "test_dataset = MapillaryDataset(test_df, transform = transform_val_test)\n",
    "test_grd_truth = torch.tensor(test_df.region.isin(ood_regions).astype(int).values) # 0 as ID, 1 as OOD\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, num_workers=6, pin_memory=True)\n",
    "model.eval()\n",
    "test_orig_Y_all, test_X_duplicate_all, test_alpha_pred_all = compute_X_Y_alpha(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:980, balanced accuracy:0.585929837980331, accuracy:0.7656, area under curve:0.585929837980331\n",
      "TP: 117\n",
      "FN: 190\n",
      "FP: 982\n",
      "TN 3711\n"
     ]
    }
   ],
   "source": [
    "# using max alpha as threshold, use data from ood_g4\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, roc_auc_score\n",
    "threshold = 980\n",
    "max_alpha = torch.max(test_alpha_pred_all, dim=1).values\n",
    "pred = (torch.max(test_alpha_pred_all, dim=1).values < threshold).int()\n",
    "balanced_accuracy = balanced_accuracy_score(test_grd_truth, pred)\n",
    "accuracy = accuracy_score(test_grd_truth, pred)\n",
    "auc = roc_auc_score(test_grd_truth, pred)\n",
    "print(f'threshold:{threshold}, balanced accuracy:{balanced_accuracy}, accuracy:{accuracy}, area under curve:{auc}')\n",
    "\n",
    "table = true_false_table(test_grd_truth, pred)\n",
    "print('TP:',len(table[0][0]))\n",
    "print('FN:',len(table[0][1]))\n",
    "print('FP:',len(table[1][0]))\n",
    "print('TN',len(table[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:45,  5.14it/s]\n"
     ]
    }
   ],
   "source": [
    "other_df = pd.read_csv('/lab/project-1/train_other_signs.csv').iloc[:5000]\n",
    "test_df_less = pd.read_csv('/lab/project-1/test_label.csv').iloc[:2500]\n",
    "full_df = pd.concat([test_df_less,other_df])\n",
    "mix_sign_dataset = MapillaryDataset(full_df, transform = transform_val_test)\n",
    "grd_truth1 = torch.tensor(test_df_less.region.isin(ood_regions).astype(int).values) # 0 as ID, 1 as OOD\n",
    "grd_truth2 = torch.ones(5000)\n",
    "mix_grd_truth = torch.cat([grd_truth1, grd_truth2])\n",
    "mix_sign_loader = torch.utils.data.DataLoader(mix_sign_dataset,\n",
    "                                                      batch_size=32,\n",
    "                                                      num_workers=6, pin_memory=True)\n",
    "mix_orig_Y_all, mix_X_duplicate_all, mix_alpha_pred_all = compute_X_Y_alpha(model, mix_sign_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:980, balanced accuracy:0.7577569071755118, accuracy:0.7465333333333334, area under curve:0.7577569071755118\n",
      "TP: 3756\n",
      "FN: 1404\n",
      "FP: 497\n",
      "TN 1843\n"
     ]
    }
   ],
   "source": [
    "# using max alpha as threshold, use data from ood_g4\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, roc_auc_score\n",
    "threshold = 980\n",
    "max_alpha = torch.max(mix_alpha_pred_all, dim=1).values\n",
    "pred = (torch.max(mix_alpha_pred_all, dim=1).values < threshold).int()\n",
    "balanced_accuracy = balanced_accuracy_score(mix_grd_truth, pred)\n",
    "accuracy = accuracy_score(mix_grd_truth, pred)\n",
    "auc = roc_auc_score(mix_grd_truth, pred)\n",
    "print(f'threshold:{threshold}, balanced accuracy:{balanced_accuracy}, accuracy:{accuracy}, area under curve:{auc}')\n",
    "\n",
    "table = true_false_table(mix_grd_truth, pred)\n",
    "print('TP:',len(table[0][0]))\n",
    "print('FN:',len(table[0][1]))\n",
    "print('FP:',len(table[1][0]))\n",
    "print('TN',len(table[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.1089e+00, 1.2509e+04, 1.0000e+00],\n",
       "        [1.0000e+00, 2.0189e+00, 1.0000e+00, 4.9233e+03],\n",
       "        [1.0000e+00, 1.0012e+00, 1.0374e+04, 1.0000e+00],\n",
       "        ...,\n",
       "        [1.2976e+03, 1.4969e+00, 1.7326e+01, 2.2678e+00],\n",
       "        [4.2470e+01, 1.9358e+00, 2.0373e+03, 1.0024e+00],\n",
       "        [1.0000e+00, 1.7508e+00, 1.1575e+04, 1.0000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_alpha_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:980, balanced accuracy:0.7396, accuracy:0.7396, area under curve:0.7577569071755118\n",
      "TP: 3698\n",
      "FN: 1302\n",
      "FP: 0\n",
      "TN 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/zhz/anaconda3/envs/postnet/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2006: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "other_alpha = mix_alpha_pred_all[-5000:]\n",
    "threshold = 980\n",
    "max_alpha = torch.max(other_alpha, dim=1).values\n",
    "pred = (torch.max(other_alpha, dim=1).values < threshold).int()\n",
    "balanced_accuracy = balanced_accuracy_score(grd_truth2, pred)\n",
    "accuracy = accuracy_score(grd_truth2, pred)\n",
    "# auc = roc_auc_score(grd_truth2, pred)\n",
    "print(f'threshold:{threshold}, balanced accuracy:{balanced_accuracy}, accuracy:{accuracy}, area under curve:{auc}')\n",
    "\n",
    "table = true_false_table(grd_truth2, pred)\n",
    "print('TP:',len(table[0][0]))\n",
    "print('FN:',len(table[0][1]))\n",
    "print('FP:',len(table[1][0]))\n",
    "print('TN',len(table[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.3928e+02, 4.9065e+01, 1.0000e+00],\n",
       "        [1.0000e+00, 5.0412e+02, 1.7244e+00, 1.0001e+00],\n",
       "        [4.1003e+02, 5.8184e+00, 1.6184e+01, 1.0002e+00],\n",
       "        ...,\n",
       "        [5.1279e+02, 2.9726e+00, 9.7363e+00, 1.0000e+00],\n",
       "        [1.0001e+00, 1.0428e+00, 1.1643e+03, 1.0000e+00],\n",
       "        [1.0058e+00, 1.4489e+00, 8.1337e+02, 1.0000e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_alpha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10ba92b1b2dd91cfc055dbd32954eae032a9ab425a70a2bf53189e576ddb11ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
